# FirstEye ‚Äî On-Device Human Presence Detection
**Ultra-light, cross-platform Wake Vision model deployed on Raspberry Pi 5, Arduino Nicla Vision, and Android**

FirstEye is a privacy-preserving, on-device human presence detection system powered by an 80√ó80 TensorFlow Lite model trained using the Wake Vision dataset.

The project demonstrates efficient edge AI deployment across three hardware classes:
- Raspberry Pi 5 (Cortex-A76, Linux)
- Arduino Nicla Vision (Cortex-M7, Microcontroller)
- Android Mobile Devices (Cortex-A720-class CPUs)

This project showcases how a single, small-footprint ML model can be optimized and deployed seamlessly across heterogeneous compute devices while maintaining high performance, real-time inference, and robustness across environments.

---

## Quick links
- Android guide ‚Üí `android/README.md`
- Nicla Vision guide ‚Üí `nicla_vision/README.md`
- Raspberry Pi 5 guide ‚Üí `raspberrypi/README.md`
- Model description ‚Üí `model_card.md`

---

## ‚≠ê Core Features

- **Fully on-device inference** ‚Äî no cloud, no streaming, privacy-first
- **Cross-platform deployment**
  - Android App (CameraX + TFLite)
  - Arduino Nicla Vision (OpenMV + MicroPython)
  - Raspberry Pi 5 (libcamera + OpenCV + TFLite Runtime)

- **Lightweight Wake Vision model**
  - wv_k_8_c_5_80_small.tflite
  - Input: 80√ó80 RGB
  - Outputs: Person / No Person (2 classes)

- **Optimized pipelines** for each device
- **Open-source model, training code, and deployment scripts**
---

## üöÄ Quick Start (By Device)
### üîµ Raspberry Pi 5
Located in:
```
deployment/RaspberryPi-Cortex-A76/
```

Includes:
- `firsteye_pi.py` (MJPEG streaming + inference)
- `requirements.txt` (numpy<2, opencv-python, tflite-runtime)
- `model/wv_k_8_c_5_80_small.tflite`
- Full README with setup instructions (venv, libcamera streaming)

### üü¢ Arduino Nicla Vision
Located in:
```
deployment/Arduino_Nicla_Vision-Cortex-M7/
```

Includes:
- `nicla_person_detect.py`
- Instructions for OpenMV IDE
- Model placed under `/model/` folder

### üü† Android (ARM Cortex-A720 Class)
Located in:
```
deployment/Mobile-ARM-Cortex-A720/
```

Includes:
- Android app project
- Instructions to update TFLite model and labels
- Build/run steps

## üß† Model Description

Model Card: `model_card.md`

**Model Name:** `wv_k_8_c_5_80_small.tflite`
- Input: **80√ó80, RGB, 3 channels**
- Shape: `[1, 80, 80, 3]`
- Output: 2 classes
  - `0` ‚Äî No Person
  - `1` ‚Äî Person
- Type: TensorFlow Lite (uint8/int8 quantized)
- Designed for ultra-efficient edge inference
- The full training pipeline, SavedModel, and exploration notebooks are in:
```
model/
```

## üìÅ Repository Structure
```
FirstEye/
‚îÇ   .gitignore
‚îÇ   LICENSE
‚îÇ   model_card.md
‚îÇ   README.md              <-- (You are reading this)
‚îÇ
‚îú‚îÄ‚îÄ dataset/               <-- (Datasets / sample sets if required)
‚îÇ
‚îú‚îÄ‚îÄ deployment/
‚îÇ   ‚îú‚îÄ‚îÄ Arduino_Nicla_Vision-Cortex-M7/
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ nicla_person_detect.py
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ README.md
‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ model/
‚îÇ   ‚îÇ       ‚îî‚îÄ‚îÄ wv_k_8_c_5_80_small.tflite
‚îÇ   ‚îÇ
‚îÇ   ‚îú‚îÄ‚îÄ Mobile-ARM-Cortex-A720/
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ README.md
‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ app/          <-- Android project
‚îÇ   ‚îÇ
‚îÇ   ‚îî‚îÄ‚îÄ RaspberryPi-Cortex-A76/
‚îÇ       ‚îú‚îÄ‚îÄ firsteye_pi.py
‚îÇ       ‚îú‚îÄ‚îÄ README.md
‚îÇ       ‚îú‚îÄ‚îÄ requirements.txt
‚îÇ       ‚îî‚îÄ‚îÄ model/
‚îÇ           ‚îî‚îÄ‚îÄ wv_k_8_c_5_80_small.tflite
‚îÇ
‚îî‚îÄ‚îÄ model/
    ‚îú‚îÄ‚îÄ Metrics.xlsx
    ‚îú‚îÄ‚îÄ model_centric_track_small.py
    ‚îú‚îÄ‚îÄ README.md
    ‚îú‚îÄ‚îÄ TechnicalReport.md
    ‚îú‚îÄ‚îÄ wv_k_8_c_5_80_small.tflite
    ‚îÇ
    ‚îú‚îÄ‚îÄ wv_k_8_c_5/
    ‚îÇ   ‚îú‚îÄ‚îÄ model_centric_track.py
    ‚îÇ   ‚îú‚îÄ‚îÄ model_centric_track_orig.py
    ‚îÇ   ‚îú‚îÄ‚îÄ TechnicalReport.md
    ‚îÇ   ‚îú‚îÄ‚îÄ wv_k_8_c_5.tflite
    ‚îÇ   ‚îî‚îÄ‚îÄ wv_k_8_c_5.tf/
    ‚îÇ       ‚îú‚îÄ‚îÄ fingerprint.pb
    ‚îÇ       ‚îú‚îÄ‚îÄ keras_metadata.pb
    ‚îÇ       ‚îú‚îÄ‚îÄ saved_model.pb
    ‚îÇ       ‚îî‚îÄ‚îÄ variables/
    ‚îÇ           ‚îú‚îÄ‚îÄ variables.data-00000-of-00001
    ‚îÇ           ‚îî‚îÄ‚îÄ variables.index
    ‚îÇ
    ‚îî‚îÄ‚îÄ wv_k_8_c_5_80_small.tf/
        ‚îú‚îÄ‚îÄ fingerprint.pb
        ‚îú‚îÄ‚îÄ keras_metadata.pb
        ‚îú‚îÄ‚îÄ saved_model.pb
        ‚îî‚îÄ‚îÄ variables/
            ‚îú‚îÄ‚îÄ variables.data-00000-of-00001
            ‚îî‚îÄ‚îÄ variables.index

```
---

## üéØ Why This Project Matters
- Shows how one TFLite model can run efficiently across three hardware classes
- Demonstrates scalable AI deployment from MCUs ‚Üí Mobiles ‚Üí SBCs
- Enables edge-only privacy for home monitoring, robotics, IoT presence sensing
- Lightweight model = low power, fast inference, tiny memory footprint

## üõ†Ô∏è How to Contribute
Pull requests are welcome!
You can contribute:
- New models
- Deployment examples
- ARM/NPU optimizations
- Benchmarking scripts

## üìú License
This project is licensed under the MIT License ‚Äî see LICENSE.

## üôå Acknowledgments
- Wake Vision dataset and challenge organizers
- TensorFlow Lite team
- Arduino + OpenMV tooling
- Raspberry Pi Foundation